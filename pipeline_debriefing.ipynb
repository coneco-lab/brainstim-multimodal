{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Hands-On TMS-EEG Preprocessing**\n",
    "\n",
    "### [Matteo De Matola](https://github.com/matteo-d-m) \n",
    "\n",
    "This notebook contains code and explanations for the hands-on TMS-EEG preprocessing activity, [Brain Stimulation & Multimodal Electrophysiological Recording](https://unitn.coursecatalogue.cineca.it/insegnamenti/2025/50512_653501_96292/2011/50513/10168?annoOrdinamento=2011&coorte=2024) course, [Master's degree in Cognitive Science](https://corsi.unitn.it/en/cognitive-science), University of Trento.\n",
    "\n",
    "We will use data from one condition and one subject of [Zazio et al. (2021)](https://www.sciencedirect.com/science/article/pii/S1388245721006714). The data are publicly available and freely reusable through [G-Node Gin](https://gin.g-node.org/) at [this](https://gin.g-node.org/AgneseZazio/ZazioMiniussiBortoletto2021) link under a [Creative Commons CC0 1.0 Universal license](https://creativecommons.org/publicdomain/zero/1.0/deed.en)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This activity will guide you through a typical TMS-EEG preprocessing pipeline. \n",
    "\n",
    "Given a signal generated by some system, _preprocessing_ is the act of separating the actual signal from the noise.\n",
    "\n",
    "In the context of TMS-EEG:\n",
    "\n",
    "- The _signal_ is the fraction of scalp voltage generated by the cerebral cortex in response to TMS pulses\n",
    "- The _noise_ is the fraction of scalp voltage generated by any non-cerebral source, including (but not limited to) muscles, eyes, and electronic instrumentation (chiefly the TMS coil itself)\n",
    "\n",
    "Preprocessing is usually a complex process that includes multiple sequential transformations of the TMS-EEG data.\n",
    "\n",
    "Such sequence of transformations is a _**preprocessing pipeline**_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no standard preprocessing pipeline for TMS-EEG data (nor for EEG data in general). \n",
    "\n",
    "The problem is significant enough to write papers about it: see [Bertazzoli et al. (2021)](https://www.sciencedirect.com/science/article/pii/S1053811921005486), [Rogasch et al., 2022](https://www.sciencedirect.com/science/article/pii/S0165027022000218?via%3Dihub), [Brancaccio et al., 2024](https://www.sciencedirect.com/science/article/pii/S1053811924003719) \n",
    "\n",
    "\n",
    "Broadly speaking, one could classify preprocessing strategies in two categories: _conservationist approaches_ and _interventionist approaches_.\n",
    "\n",
    "- _Conservationist approaches_ tend to conserve the signal as it is acquired, keeping transformations to a minimum at risk of not eliminating noise\n",
    "    - Assumption: any transformation might delete noise, but it alters the signal in potentially undesirable ways\n",
    "    - See [Delorme (2023)](https://www.nature.com/articles/s41598-023-27528-0)\n",
    "- _Interventionist approaches_ tend to act heavily on the signal, under the assumption that experimental manipulations of the EEG signal will not be visible until artefacts have been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, people tend to design pipelines that suit their experimental manipulations and the characteristics of their data. \n",
    "\n",
    "For example, if TMS is delivered on an area where there are large cranial muscles, data will probably be contaminated by large muscle artefacts. Therefore, it will be reasonable to design a pipeline that acts aggressively on muscle artefacts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path                            # to build a bridge between Python and the filesystem \n",
    "\n",
    "import numpy as np                                  # to perform array operations\n",
    "import matplotlib                                   # this and the following to draw plots\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('Qt5Agg')                            # to make plots interactive\n",
    "\n",
    "import mne                                          # to read and manipulate EEG data\n",
    "\n",
    "from scripts import utils                           # custom functions to shorten the code in this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Basic Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic preprocessing is the process of loading data, inspecting them to understand their shape and content, and applying some basic transformations that set the stage for subsequent, more complex operations.\n",
    "\n",
    "In a typical TMS-EEG preprocessing pipeline, this would include the following steps:\n",
    "\n",
    "1. Loading data\n",
    "\n",
    "2. Inspecting data\n",
    "    - Shape\n",
    "        - Number of channels and timelength\n",
    "    - Acquisition parameters\n",
    "        - Sampling rate\n",
    "    - Appearance\n",
    "        - Are the raw data visibly dirty?\n",
    "3. Adjusting data \n",
    "    - If present, drop non-EEG channels (EMG, EOG, ECG)\n",
    "    - Set channel locations\n",
    "    \n",
    "4. Interpolating the pulse artifact\n",
    "\n",
    "5. High-pass filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.1 Loading Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step amounts merely to reading the data files. \n",
    "\n",
    "EEG data files come in a variety of formats, depending on the recording system and the choices made by researchers. \n",
    "\n",
    "The four most common formats are (in no particular order):\n",
    "\n",
    "1. BrainVision format: `.eeg` + `.vhdr` + `.vmrk` = one single recording\n",
    "    - Typical of data acquired with Brain Products hardware, which usually ships with the BrainVision Recorder software\n",
    "\n",
    "2. EEGLAB format: `.set` + `.fdt` = one single recording \n",
    "    - Typical of data that were previously analysed or otherwise treated with EEGLAB, the main Matlab-based EEG toolbox\n",
    "    - Some recording systems (e.g., Bittium NeurOne) have a built-in option to save data in this format to facilitate EEGLAB users\n",
    "\n",
    "3. Matlab format: `.mat`\n",
    "    - Typycal of recording systems that run Matlab-based software (e.g., g.tec systems)\n",
    "\n",
    "4. European Data Format: `.edf` \n",
    "\n",
    "MNE-Python has functions to read data in all the formats above, except `.mat` which is probably the least common. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity we will use data acquired with Brain Products hardware and stored in BrainVision format.\n",
    "\n",
    "As mentioned above, the BrainVision format distributes information across three different files: \n",
    "\n",
    "1. The `.eeg` file, which contains actual EEG time series \n",
    "2. The `.vhdr` file (also known as _header file_), which contains important metadata about _how_ the data were acquired &mdash; chiefly, the map between channel labels (e.g., `Fp1`) and their place in the recording hardware (e.g., _pin number one_)\n",
    "3. The `.vmrk` file (also known as _marker file_), which contains important information about event markers &mdash; that is, _when_ an event like a TMS pulse happened and _how long_ did it last\n",
    "\n",
    "To read data in BrainVision format, the go-to function is `read_raw_brainvision()`, contained in module `io` (that is, input/output) of the `mne` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below performes the following operations:\n",
    "\n",
    "- Define a `Path` object (basically, make the data directory accessible to Python)\n",
    "- Identify the file of interest\n",
    "- Read it using `read_raw_brainvision()`\n",
    "- Assign the result to a Python variable, where EEG data will be represented as a `channels x time` matrix with accompanying metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"data\")\n",
    "subject_and_condition = \"S02C1_M1\"\n",
    "\n",
    "file_of_interest = list(data_dir.glob(pattern=f\"{subject_and_condition}.vhdr\"))\n",
    "eeg_data = mne.io.read_raw_brainvision(vhdr_fname=file_of_interest[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the file to read is not the  EEG file itself (`.eeg`), but the header file (`.vhdr`). \n",
    "\n",
    "This is because the header contains metadata that are needed to correctly interpret the information from the EEG file, which would otherwise be a meaningless array of numbers. \n",
    "- The same goes for the EEGLAB format, where the file to read is the `.fdt` that contains metadata \n",
    "\n",
    "After reading the header, `read_raw_brainvision()` proceeds to read the actual data from the corresponding EEG file. This implies that the two filenames **must** be identical (except for the extension), otherwise Python will throw an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading the data, it is possible to start inspecting them by printing the name of the corresponding Python variable. \n",
    "\n",
    "This gives access to a first set of useful information concerning the acquisition set-up, the channels and the filters that were applied to the signal during the recording. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, information is classified as `General`, `Acquisition`, `Channels`, and `Filters`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `General` section yields no particular insights. \n",
    "\n",
    "Much more interesting is the `Acquisition` section, which describes the temporal characteristics of the data: the duration of the recording, the sampling rate, and the number of timepoints. \n",
    "\n",
    "We shall now pause for a minute and ponder the relationship between these three quantities ðŸ¤”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that:\n",
    "\n",
    "- The recording length is expressed in minutes (which are a multiple of seconds)\n",
    "- The sampling rate is expressed in Hz (that is, samples per second)\n",
    "- The number of timepoints is expressed in array units &mdash; in other words, it is: \n",
    "    - The number of points on the horizontal axis of the array that stores the EEG data\n",
    "    - The number of columns in the EEG data matrix\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./files/eeg.png\" width=\"500\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "The three quantities (minutes, Hz, array units) have _time_ in common &mdash; therefore, it is possible to convert from one to another with simple operations. This is useful to acquire a deeper undestanding of things and to recover one quantity from the other two (should that become necessary).\n",
    "\n",
    "The following relationships are particularly useful when you have to [wrangle](https://en.wikipedia.org/wiki/Data_wrangling) with ill-defined data:\n",
    "\n",
    "$$ \\text{Number \\ of \\ Timepoints} = \\text{Recording  \\ Length in Minutes} \\cdot \\text{Sampling \\ Rate} $$\n",
    "\n",
    "$$ \\text{Recording  \\ Length in Minutes} = \\Bigg(\\dfrac{\\text{Number \\ of \\ Timepoints}}{\\text{Sampling \\ Rate}}\\Bigg) \\cdot \\dfrac{1}{60}$$\n",
    "\n",
    "where $60$ is the number of seconds in a minute. You can check for yourself that the following results are coherent with what you find in the dataset's info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_OF_TIMEPOINTS = len(eeg_data.times)\n",
    "SAMPLING_RATE = eeg_data.info[\"sfreq\"]\n",
    "SECONDS_IN_A_MINUTE = 60\n",
    "\n",
    "RECORDING_LENGTH_IN_MINUTES = NUMBER_OF_TIMEPOINTS / SAMPLING_RATE / SECONDS_IN_A_MINUTE\n",
    "print(f\"The recording length is: {RECORDING_LENGTH_IN_MINUTES}\")\n",
    "\n",
    "NUMBER_OF_TIMEPOINTS = RECORDING_LENGTH_IN_MINUTES*SAMPLING_RATE*SECONDS_IN_A_MINUTE\n",
    "print(f\"The number of timepoints is: {NUMBER_OF_TIMEPOINTS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Channels` section is also interesting, as it contains information about the number of channels and whether their position was [digitised](https://www.nature.com/articles/s41598-023-30223-9) during the recording. As you can see from the table above, no digitisation was performed. However, the list of channels is available and can be accessed as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data.ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2 Drop Unwanted Channels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you could see from the list above, the dataset contains EEG channels (`Fp1`,`Fpz`,`Fp2`... etc.) as well as non-EEG channels (`EOG` and `FDI`).\n",
    "\n",
    "Assuming that we are not interested in analysing non-EEG channels, we can drop them. To this end, we need to identify them. This can either be done manually (which would be boring and time-consuming) or automatically. In the latter case, one can exploit the fact that the last character in EEG channel names tends to be an integer number (`Fp1`, `Fp2`, `AF7`...) or a lowercase _z_ (`Fpz`, `Cz`, `Oz`...). The following code does just that: for each channel name, it checks if its last character is an integer. If it is not (that is, if Python throws a `ValueError`), it checks if such character is a _z_. If it is not, the channel must be non-EEG and is thus appended to a list of channels that need be dropped. \n",
    "\n",
    "You can check for yourself that the resulting list contains only channels with a non-EEG name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_to_drop = []\n",
    "\n",
    "for channel_name in eeg_data.ch_names:\n",
    "    try:\n",
    "        int(channel_name[-1])\n",
    "    except ValueError:\n",
    "        if channel_name[-1] != \"z\": \n",
    "            channels_to_drop.append(channel_name)\n",
    "print(f\"Channels to drop: {channels_to_drop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After identifying the channels to drop, one can actually drop them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data = eeg_data.drop_channels(ch_names=channels_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-printing dataset info shows that the data now have 70 channels, which is two less than before (as expected):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3 Set Channel Locations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As revealed by its info, the dataset contains no _Head & sensor digitization_ &mdash; in other words, we have no way to know the shape of the head nor the position of channels relative to it. \n",
    "\n",
    "However, this is fundamental information for some analyses (_source reconstruction_) and visualizations (_topoplots_).\n",
    "\n",
    "While we will not perform source reconstruction, we will visualize topoplots &mdash; that is, colour-coded scalp voltage maps. \n",
    "\n",
    "Therefore, we need to associate each channel to a set of coordinates (called _montage_) that locate them on the head. To this end, MNE has a list of built-in coordinate sets that can be printed as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.channels.get_builtin_montages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know from the publication that the authors used a 74-channels Brain Products cap, which should correspond to MNE's `easycap-M1` montage. \n",
    "\n",
    "Therefore, we can create a corresponding _montage_ object and print the resulting $x,y,z$ coordinates for each channel and the three fiducial points: nasion, left pre-auricular (LPA) and right pre-auricular (RPA): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easycap_m1_montage = mne.channels.make_standard_montage(kind=\"easycap-M1\")\n",
    "easycap_m1_montage.get_positions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having 3D coordinates, we can project them onto a plane and build the following plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easycap_m1_montage.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having visualized the montage and ascertained that it makes sense, we can apply it to our data as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data.set_montage(montage=easycap_m1_montage,\n",
    "                     on_missing=\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finally ready to visualize the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_data.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be to interpolate the TMS pulse artefact. To this end, we need to locate TMS pulses on the EEG trace. Therefore, we need information about _when_ TMS pulses occurred during the experiment.\n",
    "\n",
    "This information is given by **event markers**: timestamps that locate events of experimental interest on the EEG trace. These timestamps have three defining characteristics:\n",
    "\n",
    "1. A name: for example, a numeric code like `54` or a short word like `tms`\n",
    "2. A duration \n",
    "3. A time of occurrence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the BrainVision data format, marker information are stored in the `.vmrk` file and are enriched by some supplementary information. In fact, they are defined by:\n",
    "\n",
    "1. An ordinal number\n",
    "2. A type\n",
    "3. A name\n",
    "4. A time of occurrence (in units of data points)\n",
    "5. A duration (in units of data points)\n",
    "6. Information about which channels are involved\n",
    "\n",
    "For example, the following row of the marker file tells us that marker number 200 (`Mk200`) is of type `Stimulus`, its name is `S 54`, it occurred at time point `3183619`, it lasted one instant (`1`), and it affected all channels (in the BrainVision convention, `0` means \"all channels\"):\n",
    "\n",
    "`Mk200=Stimulus,S 54,3183619,1,0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNE has a built-in function to extract marker information from EEG data structures. \n",
    "\n",
    "The function is called `events_from_annotations()` and its goal is to translate events data into a Python-friendly format:\n",
    "\n",
    "1. One array with as many rows as there are events (in our case, 200) and three columns: \\\n",
    "one for the time of occurrence, one for the affected channels, and one for the event's name\n",
    "2. One dictionary that associates each event name to a number-only format. \\\n",
    "This one is of secondary importance for the sake of understanding the event, as the name is arbitrary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_from_annotations, events_dict = mne.events_from_annotations(raw=eeg_data)\n",
    "events_from_annotations = events_from_annotations[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.4. Interpolate the Pulse Artefact: Rationale & Execution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TMS pulse leaves a large artifact on EEG traces ([Veniero et al., 2009](https://www.sciencedirect.com/science/article/pii/S1388245709003629), [Freche et al., 2018](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006177)). \n",
    "\n",
    "This artifact is due to the interaction between the EEG recording system and the electric field induced by the pulse, which is orders of magnitude larger than physiological fields. \n",
    "\n",
    "The following code creates epochs around TMS pulses, averages them, and plots the resulting TEP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_interpolation_epochs = mne.Epochs(raw=eeg_data,\n",
    "                                      events=events_from_annotations,\n",
    "                                      tmin=-1.1,\n",
    "                                      tmax=0.5,\n",
    "                                      baseline=None)\n",
    "pre_interpolation_epochs_tep = pre_interpolation_epochs.average()\n",
    "pre_interpolation_epochs_tep.plot();\n",
    "del pre_interpolation_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the EEG traces are dominated by a large spike at the time of the TMS pulse &mdash; so large that everything else appears flat. That is the pulse artifact. \n",
    "\n",
    "There is currently no way to recover physiological signals from a pulse artifact. One can only delete the artifact and interpolate the empty window underneath. \n",
    "\n",
    "Interpolation is the act of estimating a function in some interval, given values from a preceding and a following interval. \n",
    "\n",
    "In other words, interpolation answers the question: \"**Given the pre- and post-pulse EEG, what should the EEG around the pulse look like?**\"\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./files/interpolation.png\" width=\"1000\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist a wealth of interpolation methods. Historically, the TMS-EEG community has adopted the following: \n",
    "\n",
    "- Replacing the artifact window with zeroes\n",
    "    - Gives up on guessing what happened in the brain during the pulse\n",
    "    - Can affect downstream computations due to the massive presence of zeroes \n",
    "- Linear interpolation \n",
    "    - Fits a linear function in the artifact window\n",
    "    - Implausible: the EEG is seldom linear\n",
    "- Moving average interpolation \n",
    "    - Replaces the artifact with a moving average that starts before the pulse\n",
    "    - Reasonable approach but suboptimal results\n",
    "- Cubic spline interpolation \n",
    "    - Fits a cubic function between each pair of contiguous `(time, voltage)` points in the interval of interest\n",
    "    - Reasonable approach and satisfying results &mdash; current state of the art  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code loads data that were were previously interpolated with a cubic spline between 2 ms pre-pulse and 5 ms post-pulse, then segments the signal into epochs and computes the corresponding TEP for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_interpolation_eeg = mne.io.read_raw(fname=\"data/post_2_5_interpolation_eeg.fif\",\n",
    "                                         preload=True)\n",
    "post_interpolation_epochs = mne.Epochs(raw=post_interpolation_eeg,\n",
    "                                       events=events_from_annotations,\n",
    "                                       tmin=-1.1,\n",
    "                                       tmax=0.5,\n",
    "                                       baseline=None)\n",
    "post_interpolation_tep = post_interpolation_epochs.average()\n",
    "post_interpolation_tep.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.5. High-Pass Filtering: Rationale & Execution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering is the convolution* of a signal with a kernel whose characteristics can highlight a pattern of interest while suppressing other patterns.\n",
    "\n",
    "For example, high-pass filtering with a cut frequency (or _threshold_) $\\tau$ is the convolution of the signal with a kernel that highlights  high-frequency components, where \"high\" means \"larger than $\\tau$\". \n",
    "\n",
    "We are interested in high-pass filtering the data to discard all frequencies below 0.1 Hz, preserving others. Oscillations at very low frequencies (so-called _slow drifts_) are usually due to slow-cycling local currents that are generated at the scalp by processes like sweating or the exchange of ions between the electrode and the electrode gel, so they are not interested for scientific purposes.\n",
    "\n",
    "---\n",
    "\n",
    "*_Convolution is a mathematical operation that cannot be fully understood without some basics of linear algebra and calculus. \n",
    "However, people without a quantitative background can get a working understanding of convolution from resources like [this article](https://betterexplained.com/articles/intuitive-convolution/) at BetterExplained or the appropriate chapters from the book \"Analyzing Neural Time Series Data\", by Mike X Cohen (MIT Press) (available from [BUR &mdash; Rovereto University Library](https://www.biblioteca.unitn.it/en/bur-rovereto-university-library)). \n",
    "Finally, [de CheveignÃ© & Nelken (2019)](https://www.sciencedirect.com/science/article/pii/S0896627319301746) provide a good introduction to filters and their use in EEG._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_filtering_eeg = mne.filter.filter_data(data=post_interpolation_eeg.get_data(),\n",
    "                                            sfreq=post_interpolation_eeg.info[\"sfreq\"],\n",
    "                                            l_freq=0.1,\n",
    "                                            h_freq=None,\n",
    "                                            method=\"iir\",\n",
    "                                            iir_params=None,\n",
    "                                            copy=True,\n",
    "                                            phase=\"zero\")\n",
    "post_filtering_eeg = mne.io.RawArray(data=post_filtering_eeg,\n",
    "                                     info=post_interpolation_eeg.info)\n",
    "post_filtering_epochs = mne.Epochs(raw=post_filtering_eeg,\n",
    "                                   events=events_from_annotations,\n",
    "                                   tmin=-1.1,\n",
    "                                   tmax=0.5,\n",
    "                                   baseline=None)\n",
    "post_filtering_tep = post_filtering_epochs.average()\n",
    "post_filtering_tep.plot();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
